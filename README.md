# Pump it Up: Data Mining the Water Table

![Competition Badge](https://img.shields.io/badge/DrivenData-Competition-blue)
![Accuracy](https://img.shields.io/badge/Best_Accuracy-82.06%25-green)
![Python](https://img.shields.io/badge/Python-3.x-blue)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)

Proyecto de Machine Learning para la competiciÃ³n [Pump it Up: Data Mining the Water Table](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table) de DrivenData.

**Autor:** Antonio Luis MartÃ­nez Trapote  
**Fecha:** Junio 2025  
**Trabajo final del mÃ³dulo de Machine Learning - UCM**

> âš ï¸ **NOTA IMPORTANTE**: Este repositorio contiene Ãºnicamente el cÃ³digo del proyecto. Los datos de la competiciÃ³n NO estÃ¡n incluidos para cumplir con las reglas de DrivenData. Consulta [DATA.md](DATA.md) para obtener instrucciones sobre cÃ³mo conseguir los datos.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto aborda el desafÃ­o de predecir el estado operacional de bombas de agua en Tanzania utilizando tÃ©cnicas de Machine Learning. El objetivo es clasificar las bombas de agua en tres categorÃ­as:

- **Functional**: Bombas que funcionan correctamente
- **Functional needs repair**: Bombas que funcionan pero necesitan reparaciÃ³n
- **Non functional**: Bombas que no funcionan

## ğŸ¯ Resultados Principales

- **Mejor Accuracy en competiciÃ³n:** 82.06%
- **Modelo final:** CatBoostClassifier con RandomSearchCV
- **PosiciÃ³n en leaderboard:** [Incluir posiciÃ³n si estÃ¡ disponible]

## ğŸ“Š MetodologÃ­a

### 1. AnÃ¡lisis Exploratorio de Datos (EDA)
- AnÃ¡lisis de variables categÃ³ricas y numÃ©ricas
- IdentificaciÃ³n de patrones y correlaciones
- Tratamiento de valores faltantes y atÃ­picos

### 2. Feature Engineering
- CreaciÃ³n de nuevas variables a partir de las existentes
- Tratamiento de variables de alta cardinalidad
- Encoding de variables categÃ³ricas
- Manejo de variables con alta proporciÃ³n de zeros

### 3. Modelos Evaluados
- **Random Forest**
- **CatBoost** (Modelo final)
- **Logistic Regression**
- ComparaciÃ³n de mÃºltiples configuraciones y hiperparÃ¡metros

### 4. OptimizaciÃ³n
- **RandomSearchCV** para optimizaciÃ³n de hiperparÃ¡metros
- **ValidaciÃ³n cruzada** para evaluaciÃ³n robusta
- **Early stopping** para prevenir overfitting

## ğŸ—‚ï¸ Estructura del Proyecto

```
PumpItUp_project/
â”œâ”€â”€ PumpItUp_AntonioTrapote.ipynb    # Notebook principal con todo el anÃ¡lisis
â”œâ”€â”€ README.md                        # DocumentaciÃ³n del proyecto
â”œâ”€â”€ DATA.md                          # Instrucciones para obtener los datos
â”œâ”€â”€ LICENSE                          # Licencia MIT (requerida por DrivenData)
â”œâ”€â”€ requirements.txt                 # Dependencias de Python
â”œâ”€â”€ setup.sh                         # Script de configuraciÃ³n automÃ¡tica
â”œâ”€â”€ test_environment.py              # Script de verificaciÃ³n de dependencias
â”œâ”€â”€ check_compliance.sh              # Script de verificaciÃ³n de cumplimiento
â”œâ”€â”€ .gitignore                       # ProtecciÃ³n de archivos sensibles
â””â”€â”€ [datos]                          # Archivos CSV (no incluidos en repo)
    â”œâ”€â”€ training_values.csv          # Datos de entrenamiento (obtener de DrivenData)
    â”œâ”€â”€ training_labels.csv          # Etiquetas de entrenamiento (obtener de DrivenData)
    â””â”€â”€ test_values.csv              # Datos de test (obtener de DrivenData)
```

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### Prerequisitos
- Python 3.8+
- Jupyter Notebook o VS Code
- Git

### InstalaciÃ³n

#### Paso 1: Obtener los Datos
âš ï¸ **Primero debes obtener los datos de la competiciÃ³n**. Consulta [DATA.md](DATA.md) para instrucciones detalladas.

#### Paso 2: Configurar el Proyecto

##### OpciÃ³n A: ConfiguraciÃ³n AutomÃ¡tica (Recomendada)
```bash
chmod +x setup.sh
./setup.sh
```

##### OpciÃ³n B: ConfiguraciÃ³n Manual

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/PumpItUp_project.git
cd PumpItUp_project
```

2. **Crear entorno virtual**
```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Verificar instalaciÃ³n**
```bash
python test_environment.py
```

5. **Verificar cumplimiento de reglas** (opcional)
```bash
./check_compliance.sh
```

6. **Ejecutar el notebook**
```bash
jupyter notebook PumpItUp_AntonioTrapote.ipynb
```

## ğŸ“ˆ Resultados de Modelos

| Modelo | Accuracy CV | Accuracy CompeticiÃ³n | Notas |
|--------|-------------|---------------------|-------|
| Random Forest | ~0.79 | ~0.79 | Modelo baseline |
| CatBoost (bÃ¡sico) | ~0.80 | ~0.82 | Mejor rendimiento inicial |
| CatBoost + GridSearch | 0.8057 | **0.8206** | Mejor modelo final |
| CatBoost + Early Stop | 0.7998 | 0.8142 | PrevenciÃ³n overfitting |

## ğŸ” CaracterÃ­sticas Principales del AnÃ¡lisis

### Variables MÃ¡s Importantes
- **gps_height**: Altura GPS de la bomba
- **quantity**: Cantidad de agua disponible
- **waterpoint_type**: Tipo de punto de agua
- **lga**: Ãrea de gobierno local
- **ward**: Distrito administrativo

### TÃ©cnicas de Feature Engineering
- AgrupaciÃ³n de categorÃ­as con baja frecuencia
- CreaciÃ³n de variables de interacciÃ³n
- Tratamiento especial de variables geogrÃ¡ficas
- Encoding optimizado para modelos de boosting

## ğŸ“š Aprendizajes y Mejoras Futuras

### Aprendizajes Clave
- Importancia del feature engineering en competiciones de ML
- Ventajas de CatBoost para variables categÃ³ricas de alta cardinalidad
- Balance entre prevenciÃ³n de overfitting y rendimiento en competiciÃ³n

### Posibles Mejoras
- [ ] Implementar pipeline de transformaciones para producciÃ³n
- [ ] Explorar tÃ©cnicas de selecciÃ³n automÃ¡tica de features
- [ ] Probar modelos de ensemble mÃ¡s sofisticados
- [ ] AnÃ¡lisis mÃ¡s profundo de variables geogrÃ¡ficas
- [ ] Implementar validaciÃ³n temporal si fuera relevante

## ğŸ“ Notas Importantes

> **VisualizaciÃ³n:** Este notebook contiene imÃ¡genes insertadas como adjuntos que pueden no visualizarse correctamente en Google Colab. Se recomienda abrirlo en Jupyter Notebook o VS Code para ver todos los grÃ¡ficos.

> **CÃ³digo Comentado:** El notebook incluye mÃºltiples bloques de cÃ³digo comentados que representan diferentes enfoques y experimentos realizados durante el desarrollo.

## ğŸ† CompeticiÃ³n

- **Plataforma:** [DrivenData](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table)
- **Tipo:** ClasificaciÃ³n multiclase
- **MÃ©trica:** Accuracy
- **Dataset:** ~60,000 registros de entrenamiento, ~15,000 de test

## ğŸ“„ Licencia y Cumplimiento

Este proyecto estÃ¡ licenciado bajo la **MIT License** segÃºn se requiere por las reglas de la competiciÃ³n DrivenData.

### ğŸ”’ Cumplimiento de Reglas de la CompeticiÃ³n

- âœ… **CÃ³digo**: Compartido pÃºblicamente bajo MIT License (permitido)
- âœ… **Datos**: NO incluidos en el repositorio (cumple con las reglas de DrivenData)
- âœ… **Uso**: Solo para propÃ³sitos educativos y de la competiciÃ³n

Los datos originales deben obtenerse directamente de DrivenData. Ver [DATA.md](DATA.md) para mÃ¡s informaciÃ³n.

#### VerificaciÃ³n de Cumplimiento
Puedes ejecutar el script de verificaciÃ³n para confirmar que el repositorio cumple con todas las reglas:
```bash
./check_compliance.sh
```

Este script verifica que:
- No hay archivos de datos rastreados por git
- Los archivos CSV estÃ¡n protegidos en .gitignore
- Existe la licencia MIT requerida
- Se proporcionan instrucciones para obtener los datos

## ğŸ¤ Contacto

**Antonio Luis MartÃ­nez Trapote**
- [LinkedIn](tu-linkedin) 
- [Email](tu-email)

---

â­ Si este proyecto te resulta Ãºtil, no dudes en darle una estrella en GitHub!
