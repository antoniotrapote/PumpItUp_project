# Pump it Up: Data Mining the Water Table

![Competition Badge](https://img.shields.io/badge/DrivenData-Competition-blue)
![Accuracy](https://img.shields.io/badge/Best_Accuracy-82.06%25-green)
![Python](https://img.shields.io/badge/Python-3.x-blue)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)

Proyecto de Machine Learning para la competici√≥n [Pump it Up: Data Mining the Water Table](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table) de DrivenData.

**Autor:** Antonio Luis Mart√≠nez Trapote  
**Fecha:** Junio 2025  
**Trabajo final del m√≥dulo de Machine Learning - UCM**

> ‚ö†Ô∏è **NOTA IMPORTANTE**: Este repositorio contiene √∫nicamente el c√≥digo del proyecto. Los datos de la competici√≥n NO est√°n incluidos para cumplir con las reglas de DrivenData. Consulta [DATA.md](DATA.md) para obtener instrucciones sobre c√≥mo conseguir los datos.

## üìã Descripci√≥n del Proyecto

Este proyecto aborda el desaf√≠o de predecir el estado operacional de bombas de agua en Tanzania utilizando t√©cnicas de Machine Learning. El objetivo es clasificar las bombas de agua en tres categor√≠as:

- **Functional**: Bombas que funcionan correctamente
- **Functional needs repair**: Bombas que funcionan pero necesitan reparaci√≥n
- **Non functional**: Bombas que no funcionan

## üéØ Resultados Principales

- **Mejor Accuracy en competici√≥n:** 82.06%
- **Modelo final:** CatBoostClassifier con RandomSearchCV
- **Posici√≥n en leaderboard:** [Incluir posici√≥n si est√° disponible]

## üìä Metodolog√≠a

### 1. An√°lisis Exploratorio de Datos (EDA)
- An√°lisis de variables categ√≥ricas y num√©ricas
- Identificaci√≥n de patrones y correlaciones
- Tratamiento de valores faltantes y at√≠picos

### 2. Feature Engineering
- Creaci√≥n de nuevas variables a partir de las existentes
- Tratamiento de variables de alta cardinalidad
- Encoding de variables categ√≥ricas
- Manejo de variables con alta proporci√≥n de zeros

### 3. Modelos Evaluados
- **Random Forest**
- **CatBoost** (Modelo final)
- **Logistic Regression**
- Comparaci√≥n de m√∫ltiples configuraciones y hiperpar√°metros

### 4. Optimizaci√≥n
- **RandomSearchCV** para optimizaci√≥n de hiperpar√°metros
- **Validaci√≥n cruzada** para evaluaci√≥n robusta
- **Early stopping** para prevenir overfitting

## üóÇÔ∏è Estructura del Proyecto

```
PumpItUp_project/
‚îú‚îÄ‚îÄ PumpItUp_AntonioTrapote.ipynb    # Notebook principal con todo el an√°lisis
‚îú‚îÄ‚îÄ README.md                        # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ DATA.md                          # Instrucciones para obtener los datos
‚îú‚îÄ‚îÄ LICENSE                          # Licencia MIT (requerida por DrivenData)
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias de Python
‚îú‚îÄ‚îÄ setup.sh                         # Script de configuraci√≥n autom√°tica
‚îú‚îÄ‚îÄ test_environment.py              # Script de verificaci√≥n de dependencias
‚îú‚îÄ‚îÄ check_compliance.sh              # Script de verificaci√≥n de cumplimiento
‚îú‚îÄ‚îÄ .gitignore                       # Protecci√≥n de archivos sensibles
‚îî‚îÄ‚îÄ [datos]                          # Archivos CSV (no incluidos en repo)
    ‚îú‚îÄ‚îÄ training_values.csv          # Datos de entrenamiento (obtener de DrivenData)
    ‚îú‚îÄ‚îÄ training_labels.csv          # Etiquetas de entrenamiento (obtener de DrivenData)
    ‚îî‚îÄ‚îÄ test_values.csv              # Datos de test (obtener de DrivenData)
```

## üöÄ C√≥mo Ejecutar el Proyecto

### Prerequisitos
- Python 3.8+
- Jupyter Notebook o VS Code
- Git

### Instalaci√≥n

#### Paso 1: Obtener los Datos
‚ö†Ô∏è **Primero debes obtener los datos de la competici√≥n**. Consulta [DATA.md](DATA.md) para instrucciones detalladas.

#### Paso 2: Configurar el Proyecto

##### Opci√≥n A: Configuraci√≥n Autom√°tica (Recomendada)
```bash
chmod +x setup.sh
./setup.sh
```

##### Opci√≥n B: Configuraci√≥n Manual

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/PumpItUp_project.git
cd PumpItUp_project
```

2. **Crear entorno virtual**
```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Verificar instalaci√≥n**
```bash
python test_environment.py
```

5. **Verificar cumplimiento de reglas** (opcional)
```bash
./check_compliance.sh
```

6. **Ejecutar el notebook**
```bash
jupyter notebook PumpItUp_AntonioTrapote.ipynb
```

## üìà Resultados de Modelos

| Modelo | Accuracy CV | Accuracy Competici√≥n | Notas |
|--------|-------------|---------------------|-------|
| Random Forest | ~0.79 | ~0.79 | Modelo baseline |
| CatBoost (b√°sico) | ~0.80 | ~0.82 | Mejor rendimiento inicial |
| CatBoost + GridSearch | 0.8057 | **0.8206** | Mejor modelo final |
| CatBoost + Early Stop | 0.7998 | 0.8142 | Prevenci√≥n overfitting |

## üîç Caracter√≠sticas Principales del An√°lisis

### Variables M√°s Importantes
- **gps_height**: Altura GPS de la bomba
- **quantity**: Cantidad de agua disponible
- **waterpoint_type**: Tipo de punto de agua
- **lga**: √Årea de gobierno local
- **ward**: Distrito administrativo

### T√©cnicas de Feature Engineering
- Agrupaci√≥n de categor√≠as con baja frecuencia
- Creaci√≥n de variables de interacci√≥n
- Tratamiento especial de variables geogr√°ficas
- Encoding optimizado para modelos de boosting

## üìö Aprendizajes y Mejoras Futuras

### Aprendizajes Clave
- Importancia del feature engineering en competiciones de ML
- Ventajas de CatBoost para variables categ√≥ricas de alta cardinalidad
- Balance entre prevenci√≥n de overfitting y rendimiento en competici√≥n

### Posibles Mejoras
- [ ] Implementar pipeline de transformaciones para producci√≥n
- [ ] Explorar t√©cnicas de selecci√≥n autom√°tica de features
- [ ] Probar modelos de ensemble m√°s sofisticados
- [ ] An√°lisis m√°s profundo de variables geogr√°ficas
- [ ] Implementar validaci√≥n temporal si fuera relevante

## üìù Notas Importantes

> **Visualizaci√≥n:** Este notebook contiene im√°genes insertadas como adjuntos que pueden no visualizarse correctamente en Google Colab. Se recomienda abrirlo en Jupyter Notebook o VS Code para ver todos los gr√°ficos.

> **C√≥digo Comentado:** El notebook incluye m√∫ltiples bloques de c√≥digo comentados que representan diferentes enfoques y experimentos realizados durante el desarrollo.

## üèÜ Competici√≥n

- **Plataforma:** [DrivenData](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table)
- **Tipo:** Clasificaci√≥n multiclase
- **M√©trica:** Accuracy
- **Dataset:** ~60,000 registros de entrenamiento, ~15,000 de test

## üìÑ Licencia y Cumplimiento

Este proyecto est√° licenciado bajo la **MIT License** seg√∫n se requiere por las reglas de la competici√≥n DrivenData.

### üîí Cumplimiento de Reglas de la Competici√≥n

- ‚úÖ **C√≥digo**: Compartido p√∫blicamente bajo MIT License (permitido)
- ‚úÖ **Datos**: NO incluidos en el repositorio (cumple con las reglas de DrivenData)
- ‚úÖ **Uso**: Solo para prop√≥sitos educativos y de la competici√≥n

Los datos originales deben obtenerse directamente de DrivenData. Ver [DATA.md](DATA.md) para m√°s informaci√≥n.

#### Verificaci√≥n de Cumplimiento
Puedes ejecutar el script de verificaci√≥n para confirmar que el repositorio cumple con todas las reglas:
```bash
./check_compliance.sh
```

Este script verifica que:
- No hay archivos de datos rastreados por git
- Los archivos CSV est√°n protegidos en .gitignore
- Existe la licencia MIT requerida
- Se proporcionan instrucciones para obtener los datos

## ü§ù Contacto

**Antonio Luis Mart√≠nez Trapote**
- [LinkedIn](https://www.linkedin.com/in/antonio-trapote/) 

---

‚≠ê Si este proyecto te resulta √∫til, no dudes en darle una estrella en GitHub!
